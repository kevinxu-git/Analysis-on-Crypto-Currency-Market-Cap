# 3. Explore, clean, and pre-process data :
n <- dim(data)[1]
p <- dim(data)[2]
# View(data)
head(data)
dim(data)
summary(data)
t(t(names(data)))
## Missing values ?
data <- na.omit(data)
### Time series
data.ts <- data[, c(2, 8)]
library(forecast)
market.ts <- ts(data.ts$Market.Cap..., start = c(2015, 1), end = c(2019, 200), freq = 365)
plot(market.ts, xlab = "year", ylab = "Market.Cap (in $)")
# 4. Data dimension reduction
## Data summary for understanding each variables.
data.pre <- data[,-c(1,2)]
data.summary <- data.frame(mean = sapply(data.pre, mean),
sd = sapply(data.pre, sd),
min = sapply(data.pre, min),
max = sapply(data.pre, max),
median = sapply(data.pre, median),
length = sapply(data.pre, length),
miss.val = sapply(data.pre, function(x)
sum(length(which(is.na(x))))))
# maybe we need some understanding about each variables.
# find relation between two variables in our datafile
round(cor(data.pre), 2)
data.pre <- data[, -4]
## PCA
pcs <- prcomp(data.pre, scale. = TRUE)
View(data)
View(data.pre)
# 4. Data dimension reduction
## Data summary for understanding each variables.
data.pre <- data[,-c(1,2)]
data.summary <- data.frame(mean = sapply(data.pre, mean),
sd = sapply(data.pre, sd),
min = sapply(data.pre, min),
max = sapply(data.pre, max),
median = sapply(data.pre, median),
length = sapply(data.pre, length),
miss.val = sapply(data.pre, function(x)
sum(length(which(is.na(x))))))
# maybe we need some understanding about each variables.
# find relation between two variables in our datafile
round(cor(data.pre), 2)
## PCA
pcs <- prcomp(data.pre, scale. = TRUE)
summary(pcs)
pcs$rot[,1:5]
plot(pcs)
library(factoextra)
fviz_eig(pcs)
fviz_pca_var(pcs,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
# 6. Data Partition
train.index <- sample(1:n, n*0.5)
valid.index <- sample(setdiff(1:n, train.index), n*0.3)
test.index <- setdiff(1:n, union(train.index, valid.index))
# 6. Data Partition
t(t(names(data)))
# We remove the variables "X", "tx_date" for fitting the models
data.pre <- data[, -c(1, 2)]
train.index <- sample(1:n, n*0.5)
valid.index <- sample(setdiff(1:n, train.index), n*0.3)
test.index <- setdiff(1:n, union(train.index, valid.index))
train.data <- data[train.index, ]
valid.data <- data[valid.index, ]
test.data <- data[test.index, ]
# 6. Data Partition
t(t(names(data)))
# We are going to remove the variables CUM and tx_count because of high correlations
data.pre <- data[, -c(3, 10)]
# We remove the variables "X", "tx_date" in order to fit the models
train.index <- sample(1:n, n*0.5)
train.index <- sample(1:n, n*0.5)
# We remove the variables "X", "tx_date" in order to fit the models
data.pre <- data[, -c(1, 2)]
train.index <- sample(1:n, n*0.5)
# We remove the variables "X", "tx_date" in order to fit the models
data.pre <- data.pre[, -c(1, 2)]
train.index <- sample(1:n, n*0.5)
valid.index <- sample(setdiff(1:n, train.index), n*0.3)
test.index <- setdiff(1:n, union(train.index, valid.index))
train.data <- data[train.index, ]
valid.data <- data[valid.index, ]
test.data <- data[test.index, ]
rm(list=ls())
# Data import
data <- read.csv("data.csv")
# 3. Explore, clean, and pre-process data :
n <- dim(data)[1]
p <- dim(data)[2]
# View(data)
head(data)
dim(data)
summary(data)
t(t(names(data)))
## Missing values ?
data <- na.omit(data)
### Time series
library(forecast)
# 4. Data dimension reduction
## Data summary for understanding each variables.
data.pre <- data[,-c(1,2)]
data.summary <- data.frame(mean = sapply(data.pre, mean),
sd = sapply(data.pre, sd),
min = sapply(data.pre, min),
max = sapply(data.pre, max),
median = sapply(data.pre, median),
length = sapply(data.pre, length),
miss.val = sapply(data.pre, function(x)
sum(length(which(is.na(x))))))
# maybe we need some understanding about each variables.
# find relation between two variables in our datafile
round(cor(data.pre), 2)
## PCA
pcs <- prcomp(data.pre, scale. = TRUE)
summary(pcs)
pcs$rot[,1:5]
plot(pcs)
library(factoextra)
fviz_eig(pcs)
fviz_pca_var(pcs,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
# We are going to remove the variables CUM and tx_count because of high correlations
data.pre <- data[, -c(3, 10)]
# 6. Data Partition
## We remove the variables "X", "tx_date" in order to fit the models
data.pre <- data.pre[, -c(1, 2)]
train.index <- sample(1:n, n*0.5)
valid.index <- sample(setdiff(1:n, train.index), n*0.3)
test.index <- setdiff(1:n, union(train.index, valid.index))
train.data <- data[train.index, ]
valid.data <- data[valid.index, ]
test.data <- data[test.index, ]
setwd("~/Documents/Ecole_Ingé/2A/Yonsei/Courses/Data Mining/TP/Chap5_R")
rm(list=ls())
# Make Linear Model in R
library(forecast)
toyota.corolla.df <- read.csv("data/ToyotaCorolla.csv")
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(setdiff(toyota.corolla.df$Id, training), 400)
reg <- lm(Price~., data=toyota.corolla.df[,-c(1,2,8,11)], subset = training, na.action = na.exclude)
# Predict and Evaluate Performance
pred_t <- predict(reg, na.action = na.pass)
pred_v <- predict(reg, newdata = toyota.corolla.df[validation, -c(1,2,8,11)], na.action = na.pass)
accuracy(pred_t, toyota.corolla.df[training,]$Price)
accuracy(pred_v, toyota.corolla.df[validation,]$Price)
set.seed(123)  # set seed for reproducing the partition
train.index <- sample(1:n, n*0.5)
valid.index <- sample(setdiff(1:n, train.index), n*0.3)
test.index <- setdiff(1:n, union(train.index, valid.index))
train.data <- data[train.index, ]
setwd("~/Documents/Ecole_Ingé/2A/Yonsei/Courses/Data Mining/Project/DataMiningProject")
rm(list=ls())
# Data import
data <- read.csv("data.csv")
# 3. Explore, clean, and pre-process data :
n <- dim(data)[1]
p <- dim(data)[2]
# View(data)
head(data)
dim(data)
summary(data)
t(t(names(data)))
## Missing values ?
data <- na.omit(data)
## Data visualisation
### Time series
library(forecast)
market.ts <- ts(data[, c(2, 8)]$Market.Cap..., start = c(2015, 1), end = c(2019, 200), freq = 365)
plot(market.ts, xlab = "year", ylab = "Market.Cap (in $)")
# 4. Data dimension reduction
## Data summary for understanding each variables.
data.pre <- data[,-c(1,2)]
data.summary <- data.frame(mean = sapply(data.pre, mean),
sd = sapply(data.pre, sd),
min = sapply(data.pre, min),
max = sapply(data.pre, max),
median = sapply(data.pre, median),
length = sapply(data.pre, length),
miss.val = sapply(data.pre, function(x)
sum(length(which(is.na(x))))))
# maybe we need some understanding about each variables.
# find relation between two variables in our datafile
round(cor(data.pre), 2)
## PCA
pcs <- prcomp(data.pre, scale. = TRUE)
summary(pcs)
pcs$rot[,1:5]
plot(pcs)
library(factoextra)
fviz_eig(pcs)
fviz_pca_var(pcs,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
# We are going to remove the variables CUM and tx_count because of high correlations
data.pre <- data[, -c(3, 10)]
# 6. Data Partition
## We remove the variables "X", "tx_date" in order to fit the models
data.pre <- data.pre[, -c(1, 2)]
set.seed(123)  # set seed for reproducing the partition
train.index <- sample(1:n, n*0.5)
valid.index <- sample(setdiff(1:n, train.index), n*0.3)
test.index <- setdiff(1:n, union(train.index, valid.index))
train.data <- data[train.index, ]
valid.data <- data[valid.index, ]
test.data <- data[test.index, ]
train.data <- data.pre[train.index, ]
valid.data <- data.pre[valid.index, ]
test.data <- data.pre[test.index, ]
# Models
## Linear model
lm.full <- lm(Market.Cap... ~ ., data = train.df)
train.df <- data.pre[train.index, ]
valid.df <- data.pre[valid.index, ]
test.df <- data.pre[test.index, ]
# Models
## Linear model
lm.full <- lm(Market.Cap... ~ ., data = train.df)
plot(lm.full)
plot(lm.full)
summary(lm.full)
summary(lm.full)
summary(lm(Market.Cap... ~ ., data = data[train.index, ]))
summary(lm.full)
summary(lm(Market.Cap... ~ ., data = data[train.index, -c(1,2)]))
summary(lm.full)
summary(lm(Market.Cap... ~ ., data = data[train.index, -c(1,2)]))
# Models
## Linear model
lm.full <- lm(Market.Cap... ~ ., data = train.df)
plot(lm.full)
options(scipen = 999)
summary(lm.full)
library(forecast)
lm.full.pred <- predict(lm.full, valid.df)
library(forecast)
lm.full.pred <- predict(lm.full, valid.df)
# Accuracy
options(scipen=999, digits = 3)
accuracy(lm.full.pred, valid.df$Market.Cap...)
lm.full.pred
valid.df$Market.Cap...
# Accuracy
# options(scipen=999, digits = 3)
accuracy(lm.full.pred, valid.df$Market.Cap...)
pred.train <- predict(lm.full, valid.df)
lm.full.pred <- predict(lm.full, valid.df)
pred.train <- predict(lm.full, valid.df)
lm.full.pred <- predict(lm.full, valid.df)
pred.train <- predict(lm.full, valid.df)
lm.full.pred <- predict(lm.full, valid.df)
accuracy(pred.train, valid.df$Market.Cap...)
accuracy(lm.full.pred, valid.df$Market.Cap...)
pred.train <- predict(lm.full, train.df)
lm.full.pred <- predict(lm.full, valid.df)
accuracy(pred.train, valid.df$Market.Cap...)
### Evaluating Predictive Performance of linear model
library(forecast)
pred.train <- predict(lm.full, train.df)
lm.full.pred <- predict(lm.full, valid.df)
accuracy(pred.train, valid.df$Market.Cap...)
accuracy(lm.full.pred, valid.df$Market.Cap...)
36227249222-8996367533
accuracy(pred.train, train.df$Market.Cap...)
accuracy(lm.full.pred, valid.df$Market.Cap...)
### Evaluating Predictive Performance of linear model
library(forecast)
### Evaluating Predictive Performance of linear model
library(forecast)
lm.full.pred <- predict(lm.full, valid.df)
accuracy(lm.full.pred, valid.df$Market.Cap...)
gain <- gains(valid.df$Market.Cap..., lm.full.pred)
#### Lift chart
# Lift chart
library(gains)
gain <- gains(valid.df$Market.Cap..., lm.full.pred)
options(scipen=999)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Price", main="LiftChart",
type="l")
lines(c(0, valid.df$Market.Cap...) ~ c(0, n), col = "gray", lty = 2)
lines(c(0, valid.df$Market.Cap...) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
alid.df$Market.Cap...
valid.df$Market.Cap...
dim(valid.df)
dim(valid.df)[1]
#### Lift chart
# Lift chart
library(gains)
gain <- gains(valid.df$Market.Cap..., lm.full.pred)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Price", main="LiftChart",
type="l")
lines(c(0, valid.df$Market.Cap...) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
lines(c(0, valid.df$Market.Cap...) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
c(0, dim(valid.df)[1])
lines(c(0, sum(valid.df$Market.Cap...)) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
#### Lift chart
library(gains)
gain <- gains(valid.df$Market.Cap..., lm.full.pred)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Price", main="LiftChart",
type="l")
lines(c(0, sum(valid.df$Market.Cap...)) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
# Draw Decile
barplot(gain$mean.resp/mean(price), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response",
main = "Decile-wise lift chart")
# Draw Decile
barplot(gain$mean.resp/mean(valid.df$Market.Cap...), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response",
main = "Decile-wise lift chart")
# Decile-wise lift chart
barplot(gain$mean.resp/mean(valid.df$Market.Cap...), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response",
main = "Decile-wise lift chart")
mean(valid.df$Market.Cap...)
gain$mean.resp
# Decile-wise lift chart
barplot(gain$mean.resp/mean(valid.df$Market.Cap...), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response",
main = "Decile-wise lift chart")
# Exhaustive Search
library(leaps)
search <- regsubsets(Market.Cap... ~ ., data = train.df, nbest = 1, nvmax = dim(train.df)[2], method = "exhaustive")
sum <- summary(search)
summary(search)
search$nbest
# Stepwise
lm.full.step <- step(lm.full.pred, direction = "both")
# Stepwise
lm.full.step <- step(lm.full.pred, direction = "both")
search$lm.full.pred
lm.full.pred
# Stepwise
lm.full.step <- step(lm.full, direction = "both")
# Stepwise
lm.full.step <- step(lm.full, direction = "both")
summary(lm.full.step)
# Stepwise
lm.full.step <- step(lm.full, direction = "both")
norm.values <- preProcess(train.df, method=c("center", "scale"))
## KNN
### Data Normalization
train.norm.df <- train.df
valid.norm.df <- valid.df
test.norm.df <- test.df
library(caret)
norm.values <- preProcess(train.df, method=c("center", "scale"))
norm.values <- preProcess(train.df[, 1:5], method = c("center", "scale"))
train.norm.df[, 1:5] <- predict(norm.values, train.df[, 1:5])
valid.norm.df[, 1:5] <- predict(norm.values, valid.df[, 1:5])
test.norm.df[, 1:5] <- predict(norm.values, test.df[, 1:5])
library(FNN)
nn <- knn(train = train.norm.df[, 1:5], test = new.norm.df, cl = train.norm.df[, 6], k = 3)
library(class)
library(forecast)
kMax <- 5
accuracy.df <- data.frame(k = seq(1, kMax, 1), accuracy = rep(0, kMax))
for(i in 1:kMax) {
knn.pred <- class::knn(train.norm.df[, 1:5], valid.norm.df[, 1:5], cl = train.norm.df[, 6], k = i)
accuracy.df[i, 2] <- accuracy(as.numeric(knn.pred), valid.norm.df[, 6])[2]
}
accuracy.df
k <- which.min(accuracy.df[,2])
k
kMax <- 10
accuracy.df <- data.frame(k = seq(1, kMax, 1), accuracy = rep(0, kMax))
for(i in 1:kMax) {
knn.pred <- class::knn(train.norm.df[, 1:5], valid.norm.df[, 1:5], cl = train.norm.df[, 6], k = i)
accuracy.df[i, 2] <- accuracy(as.numeric(knn.pred), valid.norm.df[, 6])[2]
}
accuracy.df
k <- which.min(accuracy.df[,2])
kMax <- 20
accuracy.df <- data.frame(k = seq(1, kMax, 1), accuracy = rep(0, kMax))
for(i in 1:kMax) {
knn.pred <- class::knn(train.norm.df[, 1:5], valid.norm.df[, 1:5], cl = train.norm.df[, 6], k = i)
accuracy.df[i, 2] <- accuracy(as.numeric(knn.pred), valid.norm.df[, 6])[2]
}
accuracy.df
k <- which.min(accuracy.df[,2])
k
library(class)
library(forecast)
kMax <- 10
accuracy.df <- data.frame(k = seq(1, kMax, 1), accuracy = rep(0, kMax))
for(i in 1:kMax) {
knn.pred <- class::knn(train.norm.df[, 1:5], valid.norm.df[, 1:5], cl = train.norm.df[, 6], k = i)
accuracy.df[i, 2] <- accuracy(as.numeric(knn.pred), valid.norm.df[, 6])[2]
}
accuracy.df
k <- which.min(accuracy.df[,2])
k
### Evaluating Predictive Performance of KNN
knn.pred <- class::knn(train.norm.df[, 1:5], valid.norm.df[, 1:5], cl = train.norm.df[, 6], k = 3)
knn.pred
knn.pred
accuracy(knn.pred, valid.df$Market.Cap...)
knn.pred
str(knn.pred)
as.numeric(knn.pred)
as.numeric(as.character(knn.pred))
knn.pred <- as.numeric(as.character(knn.pred))
accuracy(knn.pred, valid.df$Market.Cap...)
all.residuals <- valid.df$Price - car.lm.pred
# Accuracy
accuracy(lm.full.pred, valid.df$Market.Cap...)
all.residuals <- valid.df$Market.Cap... - lm.full.pred
hist(all.residuals, breaks = 25, xlab = "Residuals", main = "")
accuracy(knn.pred, valid.df$Market.Cap...)
library(forecast)
lm.full.pred <- predict(lm.full, valid.df)
accuracy(lm.full.pred, valid.df$Market.Cap...)
accuracy(knn.pred, valid.df$Market.Cap...)
#### Lift chart
library(gains)
#### Lift chart
gain <- gains(valid.df$Market.Cap..., lm.full.pred)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Market.Cap...", main="LiftChart",
type="l")
lines(c(0, sum(valid.df$Market.Cap...)) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
#### Lift chart
gain <- gains(valid.df$Market.Cap..., knn.pred)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Market.Cap...", main="LiftChart",
type="l")
lines(c(0, sum(valid.df$Market.Cap...)) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
### Evaluating Predictive Performance of KNN
knn.pred <- class::knn(train.norm.df[, 1:5], valid.norm.df[, 1:5], cl = train.norm.df[, 6], k = 3)
knn.pred <- as.numeric(as.character(knn.pred))
### Evaluating Predictive Performance of linear model
accuracy(knn.pred, valid.df$Market.Cap...)
#### Lift chart
gain <- gains(valid.df$Market.Cap..., knn.pred)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Market.Cap...", main="LiftChart",
type="l")
lines(c(0, sum(valid.df$Market.Cap...)) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
#### Decile-wise lift chart
barplot(gain$mean.resp/mean(valid.df$Market.Cap...), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response",
main = "Decile-wise lift chart")
### Evaluating Predictive Performance of KNN
knn.pred <- class::knn(train.norm.df[, 1:5], valid.norm.df[, 1:5], cl = train.norm.df[, 6], k = 3)
knn.pred <- as.numeric(as.character(knn.pred))
### Evaluating Predictive Performance of linear model
accuracy(knn.pred, valid.df$Market.Cap...)
#### Lift chart
gain <- gains(valid.df$Market.Cap..., knn.pred)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Market.Cap...", main="LiftChart",
type="l")
lines(c(0, sum(valid.df$Market.Cap...)) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
#### Lift chart
library(gains)
gain <- gains(valid.df$Market.Cap..., lm.full.pred)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Market.Cap...", main="LiftChart",
type="l")
lines(c(0, sum(valid.df$Market.Cap...)) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
#### Decile-wise lift chart
barplot(gain$mean.resp/mean(valid.df$Market.Cap...), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response",
main = "Decile-wise lift chart")
as.numeric(as.character(knn.pred))accuracy(knn.pred, valid.df$Market.Cap...)
accuracy(knn.pred, valid.df$Market.Cap...)
accuracy(knn.pred, valid.df$Market.Cap...)
a <- accuracy(knn.pred, valid.df$Market.Cap...)
a
b <- accuracy(lm.full.pred, valid.df$Market.Cap...)
a
b
a-b
8996367533-32588411058
### Evaluating Predictive Performance of KNN
knn.pred <- class::knn(train.norm.df[, 1:5], valid.norm.df[, 1:5], cl = train.norm.df[, 6], k = 3)
knn.pred <- as.numeric(as.character(knn.pred))
accuracy(knn.pred, valid.df$Market.Cap...)
#### Lift chart
gain <- gains(valid.df$Market.Cap..., knn.pred)
options(scipen=999)
plot(c(0, gain$cume.pct.of.total*sum(valid.df$Market.Cap...)) ~ c(0, gain$cume.obs),
xlab="# cases", ylab="Cumulative Market.Cap...", main="LiftChart",
type="l")
lines(c(0, sum(valid.df$Market.Cap...)) ~ c(0, dim(valid.df)[1]), col = "gray", lty = 2)
#### Decile-wise lift chart
barplot(gain$mean.resp/mean(valid.df$Market.Cap...), names.arg = gain$depth,
xlab = "Percentile", ylab = "Mean Response",
main = "Decile-wise lift chart")
